% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CreateTextRepresentationSettings.R
\name{createTextRepCovariateSettings}
\alias{createTextRepCovariateSettings}
\title{createTextRepCovariateSettings}
\usage{
createTextRepCovariateSettings(
  useTextData = TRUE,
  startDay = -30,
  endDay = 0,
  preprocessor_function = tolower,
  tokenizer_function = "word",
  stopwords = NULL,
  custom_pruning_regex = NULL,
  ngrams = 1,
  vocab_term_max = Inf,
  term_count_min = 50,
  term_count_max = Inf,
  doc_count_min = 50,
  doc_count_max = Inf,
  doc_proportion_max = 0.5,
  doc_proportion_min = 0.001,
  dictionaryVocabIds = NULL,
  representations = c("tfidf"),
  vocabFile = NULL
)
}
\arguments{
\item{useTextData}{logical; option to disable the creation of text representation covariates.}

\item{startDay}{integer; start day before the index date for with the text representations have to be computed.}

\item{endDay}{integer; end day before the index date for with the text representations have to be computed.}

\item{preprocessor_function}{function; to preprocess the stings before tokenization. Default is \code{\link{tolower}}.}

\item{tokenizer_function}{character or function; to tokenize the strings. Default is quanteda tokenizer (\code{\link[quanteda]{tokens}}), with argument "word". Other possible arguments are "fasterword", "fastestword", "sentence", and "character". It is also possible to provide a custom tokenizer function. This function should take the document strings as input and should return a list of character vectors (tokens).}

\item{stopwords}{character vector; of list of stopwords that will be removed. Default is NULL. See \code{\link[stopwords]{stopwords}} for generating stopwords.}

\item{custom_pruning_regex}{(optional) character; regular expression (regex) that selects tokens that will be removed. Default is \code{NULL}.}

\item{ngrams}{integer vector; specifying the number of elements to be concatenated in each ngram. For example: \code{c(1,2)} creates all unigrams and bigrams; \code{c(1:3)} creats all unigrams, bigrams, and trigrams. Default is 1: no ngrams (unigram).}

\item{vocab_term_max}{integer; maximum number of terms in vocabulary, takes top most frequent terms. Default is \code{Inf}.}

\item{term_count_min}{integer; minimum number of occurences over all documents.}

\item{term_count_max}{integer; maximum number of occurences over all documents.Default is \code{Inf}.}

\item{doc_count_min}{integer; term will be kept when number of documents that contain this term is larger than this value.}

\item{doc_count_max}{integer; term will be kept when number of documents that contain this term is lower than this value. Default is \code{Inf}.}

\item{doc_proportion_max}{numeric; maximum proportion (0.-1.) of documents which should contain term.}

\item{doc_proportion_min}{numeric; minimum proportion (0.-1.) of documents which should contain term.}

\item{dictionaryVocabIds}{(optional) integer vector; of omop cdm vocabulary ids that are used for dictionary matching. Set to \code{NULL}(default) to turn off dictionary matching.}

\item{representations}{character vector; of text representations that should be constructed, chose from \code{"tf"} and \code{"tfidf"}. Multiple representations can be constructed at once: \code{c("tf","tfidf")}.}

\item{vocabFile}{(optional) character; file path and name for saving the vocabulary. Default is \code{NULL}.}
}
\value{
covariateSettings object, that can be used by the OHDSI FeatureExtraction package.
}
\description{
Create a covariateSettings object for constructing text representation covariates from the notes table in the OMOP CDM.
}
